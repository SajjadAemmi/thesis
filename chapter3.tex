\chapter{تئوری موضوع}
\section{مقدمه}
در سال های اخیر روش های تشخیص چهره بسیار زیادی به منظور یافتن و شناسایی چهره افراد در تصویر پیشنهاد شده است که توانایی مقاومت در برابر مشکلات و چالش های رایج مانند تغییرات شدید روشنایی، تغییر حالت و زاویه چهره، انسداد ، تاری خارج از تمرکز، سالخوردگی و... را ندارند و در کاربردهایی نظیر شرایط کنترل نشده قابل استفاده نیستند. در بخش مقدمه در مورد چالش های موجود در فرایند تشخیص چهره صحبت شد. برای رفع این چالش ها و بهبود طبقه بندی، راه حل هایی پیشنهاد شده است که در این بخش مورد بررسی قرار گرفته اند.
جدول ‏3 1- خلاصه ای از روش های مقابله با شرایط کنترل نشده


\begin{center}
\begin{tabular}{ | مقاله ها | چالش مورد نظر | رویکرد | مزیت ها | مشکل ها | } 
\hline 
 [23-26] & حالت چهره	 & تبدیل دوبعدی & 	پیچیدگی محاسباتی قابل قبول & 	استخراج نقاط ویژه باید دقیق تر باشد
 \\
\hline[22, 27-30] & حالت چهره & 	استفاده از شبکه عصبی عمیق & دقت بالا در شرایط کنترل نشده & 	پیچیدگی محاسباتی، وابستگی به داده های آموزش 
\\
\hline[11, 31-34] & حالت چهره & 	تبدیل مدل دو بعدی به سه بعدی & 	دقت بالا 	پیچیدگی محاسباتی
\\
\hline[35] & حالت چهره & 	تبدیل مدل سه بعدی به دو بعدی & 	دقت بالا 	پیچیدگی محاسباتی
\\
\hline
[26, 36] & روشنایی	 & همسان سازی بافت-نگار & 	پیچیدگی محاسباتی قابل قبول & 	قابل استفاده در تصاویر خاکستری
\\
\hline
[37, 38] & انسداد	 & استفاده از روش های شناسایی الگو و وایازش & 	دقت بالا در انسداد شدید	
\\
\hline
[39] & محدودیت داده	 & تهیه مجموعه داده با ردیابی چهره در ویدیو & 	تهیه مجموعه داده با دقت بالا & 	نیاز به یک مرحله طولانی استفاده از تصاویر ویدیو
\\
\hline
[40, 41] & محدودیت منابع & 	استفاده از رایانش ابری & 	سرعت بالا & 	تجهیزات پیشرفته و زمان تاخیر ناهمگن
\\
\hline
\end{tabular}
\end{center}

	چالش حالت 
چالش حالت زمانی پیش می آید که چهره فرد کاملا رو به روی دوربین قرار نگیرد و دارای زاویه زیادی باشد. در این شرایط با توجه به ساختار سه بعدی چهره، ممکن است سامانه نتواند ویژگی های درستی از چهره استخراج نماید و در تشخیص هویت دچار اشتباه شود. گرچه شبکه عصبی پیچشی توانایی مقابله با این چالش را از طریق استفاده از مجموعه داده های بزرگ و آموزش تصاویر مختلف از حالات چهره دارد، اما این کار باعث بزرگ شدن پایگاه داده و کند شدن سامانه می شود. استفاده از یک پی برنده  به منظور کاهش حجم داده های آموزش می تواند نتایج بهتری به دنبال داشته باشد. یکی از راه  حل های مقابله با این چالش، هنجار سازی، رو به رو سازی  و هم ترازی  چهره می باشد. در ادامه برخی رویکردهای رو به رو سازی و هم ترازی چهره در شرایط کنترل نشده را دسته بندی می کنیم.
1- رویکرد های دو بعدی با پیچیدگی محاسباتی قابل قبول (بیشتر ایده های مبتنی بر نشانه گذاری  قدیمی) مانند [23-26].
مشکل: در محیط های بدون محدودیت مانند آنچه که در این پروژه داریم، استخراج دقیق مکان نشانه های صورت از تصاویر دو بعدی نیاز به توجه بیشتری دارد. پیشرفت های اخیر مانند [23] است.
مزیت: این الگوریتم ها از نظر پیچیدگی محاسباتی  قابل قبول هستند و کاملا برای شرایط این پروژه متناسب می باشند.
2- رویکردهای مبتنی بر شبکه عصبی برای تخمین و اصلاح موقعیت چهره (آموزش و آزمایش با تصاویر دو بعدی) مانند [22, 27-30].
مشکل: این الگوریتم ها، به طور متوسط، کندتر از دسته پیشین می باشند. اما بستگی به این دارد که عمق شبکه عصبی چه مقدار باشد. وابستگی آن ها به داده های آموزش می باشد و مراحل مجزای رو به رو سازی و هم ترازی چهره ندارند.
مزیت: بدون نیاز به تصمیم گیری در مورد مجموعه بهینه ای از نشانه های چهره و دارای دقت بیشتر در شرایط کنترل نشده با انسداد و... . ایده هایی مانند [42] برای تخمین موقعیت چهره ممکن است به زمان محاسبات کمک کند.
3- رویکردهای سبک سه بعدی بدست آمده از تصاویر دو بعدی، مانند [11, 31-34].
مشکل: زمان محاسباتی بالا. یکی از امیدوار کننده ترین این الگوریتم ها در مورد پیچیدگی محاسباتی، [31] است که در شرایط بدون محدودیت آموزش دیده و آزمایش شده است. شامل مراحل مجزای رو به رو سازی و تراز بندی چهره می-باشند، اما برای محدودیت های این پروژه قابل استفاده نمی باشند.
مزیت: با استفاده از اطلاعات سه بعدی، این روش ها به بالاترین دقت تصمیم گیری در میان سه نفر رسید.
4- رویکرد های تبدیل مدل سه بعدی چهره به مدل دو بعدی چهره (روش های مبتنی بر پنجره  بر اساس چند نمایش دو بعدی مختلف از چهره) مانند [35]
مشکل: زمان محاسباتی (نه به اندازه الگوریتم های دسته سوم). 
مزیت: عملکرد بهتر در رو به رو سازی چهره در شرایط کنترل نشده نسبت به الگوریتم های دسته اول. ممکن است برای شرایط این پروژه متناسب باشند.
مرجع [43] در سال 2018 خلاصه ای از رویکردهای مختلف برای حل مسئله هم ترازی را در شکل 3-1 نشان داده است. تصویر سمت چپ، چهره ورودی می باشد. (a) هم ترازی با استفاده از تبدیلات دو بعدی ساده می باشد. (b) داده افزایی  با تغییر مقیاس، تغییر زاویه و جا به جایی می باشد. (c) برش های چندگانه می باشد. (d) داده افزایی مبتنی بر روش های سه بعدی می باشد. (e) از هیچ ابزاری برای هم ترازی مستقیم استفاده نمی نماید. اما یک شبکه را آموزش می دهد تا عامل-های مورد نیاز برای تبدیل هم ترازی را بدست آورد.
 
شکل ‏3 1 - رویکردهای مختلف هم ترازی چهره
در سال 2016، Brandon Amos و همکاران در [25] یک روش شناسایی چهره به نام OpenFace ارائه دادند که ویژگی اصلی آن ، آموزش شبکه عصبی عمیق در کمترین زمان و قابلیت اجرا بر روی دستگاه های قابل حمل مانند تلفن همراه با در نظر گرفتن منابع محدود می باشد. یک تصویر شامل تعدادی چهره به الگوریتم داده می شود. پس از یافتن چهره ها و مجزا کردن  آن ها از یکدیگر، هر چهره به طور جداگانه مورد پیش پردازش  قرار می گیرد و حجم آن کاهش می یابد. کاهش حجم تصویر برای عملکرد مناسب یک طبقه بندی بهینه بسیار مهم می باشد. تصاویر چهره ها باید هنجارسازی شده و ابعاد آن ها ثابت گردد تا به بخش شناسایی چهره راه یابند.
هر تصویر چهره باید مورد تبدیل قرار بگیرد تا چشم ها، بینی و دهان، در مکان مشخصی قرار گیرند. بدین منظور از یک تبدیل هم نسبی  دوبعدی ساده استفاده می گردد. ابتدا باید چهره توسط 68 نقطه ویژه، نشانه گذاری شود. سپس نشانه های اطراف چشم ها و بینی (شکل3-2) برای محاسبه عامل های تبدیل هم نسبی استفاده می شوند. پس از انجام تبدیل هم نسبی، تصاویر چهره برش زده شده و اندازه آن ها 96×96 پیکسل می شود.
 
شکل ‏3 2 - تبدیل هم نسبی OpenFace براساس نقاط ویژه آبی 
پس از پیش پردازش، تصاویر چهره ها به عنوان ورودی به یک شبکه عصبی پیچشی داده می شوند (شکل 3-3). این الگوریتم برای تعلیم شبکه از مجموعه داده کوچکی با 500 هزار تصویر چهره استفاده می کند که از ادغام دو مجموعه داده بزرگ برچسب گذاری شده به نام CASIA-WebFace و FaceScrub بدست آمده است. شبکه مورد استفاده در این الگوریتم یک نسخه اصلاح شده از شبکه nn4 الگوریتم FaceNet می باشد. شبکه nn4 مبتنی بر معماری GoogLeNet می باشد. برای تعیین میزان شباهت نتیجه، از فاصله اقلیدسی استفاده شده است.
 
شکل ‏3 3 - معماری OpenFace
هر تصویر از یک شبکه یکتا به یک سه گانه نگاشت داده می شود. گرادیان خطای سه گانه برای هر تصویر محاسبه شده و به عقب انتشار می یابد. در هر دسته کوچک ، P تصویر برای هر نفر از Q نفر، در مجموعه داده انتخاب می-شود. سپس M\approx PQ تصویر به شبکه داده می شود تا عملیات forward انجام پذیرد. در این مقاله از P=20 و Q=15 استفاده شده است. تمام جفت های anchor-positive برای بدست آوردن سه گانه های N=Q\binom{P}{2} مورد استفاده قرار می گیرند. خطای سه گانه محاسبه شده و مشتق آن برای پس انتشار خطا استفاده می شود. شکل 3-4 چگونگی آموزش شبکه را نشان می دهد.
 
شکل ‏3 4 - جریان یادگیری در معماری OpenFace
مجموعه داده LFW  یک معیار استاندارد برای سنجیدن میزان دقت الگوریتم های تشخیص چهره می باشد که از 13233 تصویر چهره از 5750 شخص تشکیل شده است. الگوریتم OpenFace بر روی این مجموعه داده مورد سنجش قرار گرفت که به دقت 0.9292\pm0.0134 رسید.
در سال 2016 Mohammad Haghighat و همکاران در [23] یک روش برای هنجارسازی حالت چهره بر اساس تنظیم کردن مدل  ظاهری فعال  یا AAM ارائه دادند. AAM یک مدل پارامتری است که برای ارائه یک شکل مانند چهره انسان استفاده می شود. در این الگوریتم ابتدا یک AAM بر روی تصویر چهره قرار گرفته، با روندی تکراری و به صورت بهینه شونده، بر روی چهره تنظیم می شود. سپس با استفاده از یک تبدیل هم نسبی، مرحله رو به رو سازی بر روی چهره انجام می پذیرد. شکل 3-5 رویکرد کلی این الگوریتم را نشان می دهد. 
 
شکل ‏3 5 - رویکرد کلی الگوریتم مبتنی بر AAM برای رو به رو سازی چهره
در این مدل یک تصویر چهره با مجموعه ای از نقاط ویژه هنجارسازی شده مدل می شود که به صورت [x_i.y_i] تعریف می شود که در آن i=1.\ 2.\ \ldots n . برای انجام این کار یک مرحله یادگیری نیاز است. سپس الگوریتم PCA اعمال می شود تا کاهش میزان وابستگی میان نقاط ویژه در هر مجموعه انجام می شود و نتیجه یک مدل خطی است که یک مدل شکل نمونه را به صورت زیر نمایش می دهد.
(3-1)	S=s_0+\sum_{i=1}^{n}{p_is_i}	
که در آن s_0 شکل پایه، s_i نشان دهنده i امین شکل پایه و [p_1,p_2,\ \ldots,\ p_n] عامل های شکل می-باشند. ظاهر  مدل AAM یک تصویر A(x) می باشد که در آن x مجموعه پیکسل های داخل شکل پایه s_0 می باشد. مدل ظاهر یک چهره خاص از یک ظاهر پایه a_0 و ترکیب خطی از بردارهای ویژه a_i\ ,\ \ i=1.\ 2.\ \ldots m تشکیل می شود که به صورت زیر تعریف می گردد.
(3-2)	A(x)=a_0(x)+\sum_{i=1}^{m}{q_ia_i(x)}	
که در آن [q_1,q_2,\ \ldots.,q_m] عامل های ظاهر می باشند. عامل های شکل و ظاهر برای هر تصویر در فرایند AAM بدست می آید. الگوریتم های POIC  و SIC  دو الگوریتم شناخته شده برای این منظور می باشند. رویکرد SIC نسبت به POIC در شرایطی که تصاویر آزمایشی با تصاویر آموزشی متفاوت باشند، بسیار بهتر عمل می کند. اما از طرفی دارای پیچیدگی محاسباتی بیشتری می باشد. در این مقاله از یک روش SIC سریع برای حل مسئله بهینه سازی با 100 تکرار استفاده شده است. اگر \mathbit{p}=[p_1,p_2,\ \ldots,\ p_n] مجموعه عامل های بدست آمده باشد، یک تبدیل هم نسبی قطعه ای  W(x; p) برای رو به رو سازی چهره مورد استفاده قرار می گیرد که در آن هریک از مثلث های روی توری، به صورت جداگانه به تصویر نتیجه با استفاده از درونیابی نزدیک-ترین همسایه  نگاشت پیدا می نمایند. برای مقداردهی اولیه از یک مدل پایه s_0 استفاده می شود که مقدار p در آن صفر می باشد (شکل 3-6 قسمت a). 
 
شکل ‏3 6 - مقدار دهی اولیه و بهینه سازی AAM
پس از تنظیم کامل مدل بر روی چهره، یک تبدیل هم نسبی با پارامترهای بدست آمده توسط الگوریتم یادگیری یاد شده، می تواند حالت چهره را هنجارسازی نماید. در بخش شناسایی چهره، ابتدا بخش چانه از تصویر حذف می شود زیرا چانه تقریبا تاثیری در شناسایی یک چهره ندارد. سپس تصویر چهره به اندازه 64×64 پیکسل تبدیل می شود و به 64 بخش غیر هم پوشان با اندازه 8×8 تقسیم می شود. سپس در هر بخش تبدیل DCT  انجام می شود. ضرایب خروجی تبدیل DCT بر حسب یک پویش زیگزاگی مرتب می شوند. اولین ضریب در نظر گرفته نمی شود. زیرا نشان دهنده میانگین سطح خاکستری پیکسل های بخش می باشد. 10 ضریب بعدی که ضرایب فرکانس پایین می باشند، برای ایجاد بردار ویژگی چهره استفاده می شوند. برای آموزش و آزمایش از مجموعه داده FERET و LFW استفاده شده است که در آن تصاویر چهره با زوایای چرخش متفاوت وجود دارند. الگوریتم مورد استفاده در این مقاله موفق به دستیابی به شناسایی چهره با دقت 87.3% شده است.
 
شکل ‏3 7 - نتیجه آزمایش بر روی مجموعه داده  FERETدر زاویه های متفاوت
در سال 2016، Zhang و همکاران در [29] یک روش رو به رو سازی  چهره ارائه دادند که شناسایی چهره را مستقل از نمای چهره  انجام می دهد. این الگوریتم یادگیری عمیق که VS2VI نامیده می شود، از دو بخش اصلی تشکیل شده است. بخش اول یک شبکه عصبی پیچشی برای یادگیری نما و زاویه چهره می باشد و بخش دوم از تعدادی شبکه عصبی پیچشی تشکیل شده است که هر کدام برای یادگیری تناظر  بین یک چهره از رو به رو با یک چهره از یک زاویه و نمای خاص می باشد (شکل 3-6). این الگوریتم که می تواند با تعداد کمی داده نمونه، به خوبی آموزش ببیند، دو بخش تشکیل شده از شبکه عصبی پیچشی را به هم متصل می نماید تا مشکل نمای چهره در سامانه شناسایی چهره را برطرف نماید. در این معماری برای بازسازی چهره از زاویه رو به رو از لایه های واپیچشی  به جای لایه های تمام متصل استفاده شده است.
 
شکل ‏3 8 - معماری شبکه پیشنهادی VS2VI
مدل VS2VI از دو بخش اصلی تشکیل شده است. بخش اول به عنوان ورودی یک تصویر خاکستری  شامل یک چهره در هر زاویه و نمای دلخواه با ابعاد 60×60 دریافت می کند و آن را با توجه به نمای چهره طبقه بندی  می کند. سپس تصویر وارد بخش دوم می شود که از تعدادی شبکه عصبی پیچشی که هر کدام برای یادگیری تناظر  بین یک چهره از رو به رو با یک چهره از یک زاویه و نمای خاص می باشد، تشکیل شده است. در این بخش چهره با نمای رو به رو بدست می آید و را مورد شناسایی قرار می دهیم تا هویت فرد مشخص شود. برای این منظور نیز از الگوریتم LDA  برای طبقه بندی استفاده شده است. الگوریتم LDA برای یادگیری موقعیت چهره استفاده نمی شود و فقط برای دسته بندی نهایی مورد استفاده قرار می گیرد.
 
شکل ‏3 9 – (a) معماری مدل یادگیری موقعیت چهره و (b) معماری مدل یادگیری بازسازی چهره از رو به رو
بخش اول از یک شبکه عصبی پیچشی تشکیل شده است که شامل سه لایه پیچشی، دو لایه رای گیری و یک لایه تمام متصل می باشد. ورودی آن یک تصویر با هر موقعیت و زاویه دلخواه و خروجی آن احتمال قرار داشتن تصویر ورودی در هر دسته از دسته های مربوط به نماهای مختلف می باشد. برای لایه های پیچشی از تابع فعالیت ReLU استفاده شده است. و لایه تمام متصل از softmax به عنوان تابع هزینه استفاده کرده است.
(3-3)	f(x)=max(0,x)	
بخش دوم از تعدادی زیر شبکه پیچشی که هر کدام برای یادگیری تناظر  بین چهره از رو به رو با یک چهره از یک نمای خاص می باشد، تشکیل شده است. هر یک از این زیر شبکه ها شامل دو لایه با اتصال محلی ، یک لایه رای گیری و یک لایه واپیچشی می باشند. سه لایه اول برای استخراج ویژگی ها و لایه آخر برای بازیابی چهره از رو به رو می باشند. ورودی و خروجی این لایه ها تصویر چهره می باشد.
لایه آخر به جای لایه تمام متصل از لایه واپیچشی استفاده شده است. زیرا حجم محاسبات را به طور قابل توجهی کاهش می دهد. یک لایه تماما متصل به 103 میلیون پارامتر نیاز دارد، در حالی که لایه واپیچشی به 460 هزار پارامتر نیاز دارد. لایه اول که اتصال محلی دارد،  از تابع PreLU به عنوان تابع فعالیت استفاده کرده است. لایه واپیچشی برای نمونه افزایی از درون یابی دو خطی استفاده کرده و تابع هزینه آن \ell_2-loss می باشد. برای یادگیری شبکه از الگوریتم پس انتشار خطا  استفاده شده است. الگوریتم VS2VI به دقت 95.6% در تشخیص چهره با زاویه 45 درجه رسیده است.
در سال 2018 Andrey V.Savchenko و همکاران در [44] یک روش مبتنی بر ML  برای شناسایی چهره در محیط های کنترل نشده با تعداد کم نمونه ها بر اساس محاسبه فاصله بین ویژگی های با ابعاد بالا که توسط شبکه عصبی پیچشی عمیق استخراج شده است ارائه دادند. این روش جدید شناسایی آماری، احتمال فاصله ها را نسبت به تمام تصاویر مجموعه داده ها با استفاده از قانون بیز  به حداکثر می رساند. این احتمال با تخمین توزیع هنجار طبیعی Kullback–Leibler بین ویژگی های غیرمنفی تخمین زده شده است. این رویکرد بر روی مجموعه داده های LFW، YTF  و IJB-A  مورد آزمایش قرار گرفته است. با توجه به شکل 3-14 رویکرد پیشنهادی می تواند با استفاده از فواصل سنتی، افزایش دقت 0.3 تا 5.5 درصد در مقایسه با روش های شناخته شده داشته باشد، به ویژه اگر تصاویر آموزش و آزمایش تفاوت زیادی داشته باشند. 
 
شکل ‏3 10 - مقایسه روش ارائه شده با سایر روش ها (a) تصویر آزمایشی (b) و (c) خروجی نادرست روش های دیگر (d) خروجی روش ارائه شده
در سال 2013 Marsico و همکاران در [26] یک روش رو به رو سازی چهره ارائه دادند. در ابتدا از الگوریتم STASM  برای به دست آوردن 68 نقطه ویژه بر روی چهره استفاده شده است. سپس برای هر تصویر ورودی، شاخص حالت نمونه  (SP) محاسبه می شود و در صورتی که مقدار آن کمتر از یک آستانه باشد، تصویر مردود شده و در غیر این صورت به مرحله بعد برای هنجارسازی حالت فرستاده می شود. هرچه مقدار شاخص SP بالاتر باشد، تصویر چهره به حالت تمام رخ نزدیکتر است و اصلاح زاویه کمتری نیاز دارد. شکل 3-11 قسمت a تا c معیارهای مورد نیاز برای محاسبه شاخص SP را نشان می دهد.
 
شکل ‏3 11- 6 مرحله اصلی در فرایند هنجارسازی حالت و روشنایی چهره
چرخش: چرخش سر در جهت عقربه های ساعت یا عکس آن می باشد. و به صورت زاویه 𝜃 تعریف می شود که زاویه بین خط عبوری از مرکز چشم ها و محور افقی x می باشد.
(‏3 4)
roll=min(\left|\frac{2\theta}{\pi}\right|,1)	

انحراف: چرخش در راستای محور افقی است و 𝑑r و 𝑑l فاصله مرکز چشم چپ و راست از نوک بینی می باشد. اندازه گیری این فاصله ها در صورت برابر بودن، برای تشخیص تمام رخ بودن تصویر چهره مورد استفاده قرار می گیرد.
(‏3 5)
yaw=\frac{max\left(d_l,d_r\right)-\ min(d_l,d_r)}{max(d_l,d_r)}	
شیب: چرخش سر در راستای محور عمودی را اندازه گیری می کند.
(‏3 6)
pitch=\frac{max\left(e_u,e_d\right)-\ min(e_u,e_d)}{max(e_u,e_d)}	

با محاسبه 3 شاخص فوق، شاخص SP محاسبه می شود:
(‏3 7)
SP=\ \alpha\ .(1-roll)+\ \beta\ .(1-yaw)+\ \gamma\ .(1-pitch)	

که در آن
(‏3 8)
\alpha\ +\ \beta\ +\ \gamma=1	

که مقادیر این ضرایب از طریق آزمون و خطا به دست می آیند. سپس در مرحله تمام رخ کردن تصویر چهره، بین دو فاصله 𝑑r و 𝑑l هر کدام بزرگتر باشند، نشان می دهد آن سمت از چهره بیشتر در دید دوربین است. اگر نیمه سمت راست صورت به طرف دوربین باشد (𝑑l ≥ 𝑑r )، تصویر بدون تغییر باقی می ماند. در غیر این صورت، تصویر حول محور عمودی برعکس می شود که باعث می شود همیشه نیمه سمت راست تصویر پردازش شود. سپس برای ثابت کردن طول سطرها، سطرها بسط داده می شوند. مطابق شکل 3-11 قسمت d و e نیمه سمت چپ تصویر حذف شده و از روی تصویر نیمی از چهره، نیمه دیگر نیز ساخته می شود و تصویر تمام رخ چهره به دست می آید.
	چالش روشنایی
متعادل سازی بافت نگار یکی از الگوریتم های مهم در پردازش تصویر است که هدف آن افزایش وضوح تصویر با یکنواخت سازی بافت نگار تصویر است، به گونه ای که بخش های از تصویر که به علت روشنایی کم یا زیاد، پنهان می-باشند، قابل مشاهده شوند. متعادل سازی بافت نگار قدرتمندترین و رایج ترین روش برای اصلاح روشنایی تصاویر است. اما ضعف این روش، سراسری بودن آن می باشد. برای رفع این مشکل باید از الگوریتم های محلی استفاده کرد.
در سال 2013 Marsico و همکاران در [26] یک روش هنجار سازی نورپردازی برای تصاویر چهره ارائه دادند و از این روش برای محاسبه شاخص روشنایی نمونه  (SI) استفاده کردند. زمانی که تصویر روشنایی یکنواخت دارد، بیشتر بخش های چهره توزیع یکنواخت سطح خاکستری دارند. اما وقتی روشنایی یکنواخت نباشد، برخی از نواحی خاص چهره، توزیع یکنواخت سطح خاکستری ندارند. برای مثال جلوی بینی، گونه ها و چانه معمولا نور را منعکس می کنند. 8 ناحیه در شکل 3-12 با توجه به چنین اصلی انتخاب شده اند. 8 بافت نگار با رنگ آبی و مرکز آن ها با رنگ قرمز مشاهده می شود.
 
شکل ‏3 12- اندازه گیری روشنایی و بافت نگار 8 نقطه خاص
8 بافت نگار فوق به یک توزیع یکنواخت با انحراف معیار کم در همسایگی از مرکز حجم بافت نگار اشاره دارد. بافت-نگار هر یک از ناحیه ها بدست آمده و مرکز ثقل آن محاسبه می شود:
(‏3 9)
mc\left(w\right)=\frac{\sum_{i=0}^{255}{i\times h_w(i)}}{\sum_{i=0}^{255}{h_w(i)}}	
که در آن w نشان دهنده یکی از نواحی 8 گانه می باشد. 8 مرکز جرم محاسبه شده، بردار mc را تشکیل می دهند. با توجه به فرض تشابه ذکر شده در میان نواحی صورت در نظر گرفته شده، انتظار می رود هیچ تنوع قابل توجهی در میان عناصر بردار وجود نداشته باشد و توزیع های یکسانی از سطوح خاکستری را نمایش دهند. برای دستیابی به این منظور پراکندگی مراکز حجم ها از 8 نمودار بافت نگار محاسبه شده است. سپس عناصر بردار mc توسط تابع سیگموید F در بازه ]1,0[ هنجارسازی می شوند و شاخص کیفیت روشنایی محاسبه می شود که یک عدد می باشد:
(‏3 10)
SI=1-F(std\left(mc\right))	
هرچه مقدار SI بیشتر باشد، یعنی تصویر روشنایی یکنواخت تری دارد. اگر این شاخص به اندازه کافی رضایت بخش نباشد، تصویر رد می شود. در غیر این صورت برای هنجارسازی روشنایی وارد بخش بعدی خواهد شد. در صورت رد شدن تصویر، سیاست های جایگزین برای رسیدگی به این موضوع در دسترس هستند. برای مثال ممکن است یک نمونه جدید درخواست شود که در شرایط برون خط امکان پذیر نیست. یا مداخله انسانی می تواند به صورت دستی نمونه را طبقه-بندی کند. در هر صورت بیشتر بار طبقه بندی بر دوش سامانه خواهد بود. اگر تصویر به مرحله بعد وارد شد، با استفاده از الگوریتم SQI توسط یک ماسک مربعی با اندازه 8×8 مقدار هر پیکسل بر مقدار میانگین همسایگانش تقسیم می شود و نتیجه نهایی حاصل می شود. نتیجه به صورت قسمت f در شکل  می باشد.
در سال 2015 Jamal Hussain Shah و همکاران در [36] رویکردی برای تشخیص چهره در تغییرات شدید روشنایی پیشنهاد دادند کرده اند که به سه مرحله تقسیم شده است:
	برای اصلاح روشنایی غیر یکنواخت، همسان سازی بافت نگار براساس بر اساس ناحیه استفاده می شود.
	ویژگی های مبتنی بر LDA از تصویر چهره استخراج  می شود.
	فرایند طبقه بندی بر اساس مدل OPPM انجام می شود.
	چالش انسداد
در سال 2018 Cho Ying Wu و همکاران در [38] یک رویکرد مبتنی بر وايازش  با جهت گرادیان برای شناسایی چهره های در معرض انسداد ارائه دادند. در کاربردهای واقعی، تعداد داده های آموزش بسیار کم می باشد (شاید یک تصویر به ازای هر شخص). این رویکرد توانایی برخورد با این شرایط را دارد و در مقابل تصاویری که نزدیک به 80 درصد از چهره در شرایط انسداد قرار دارد، به خوبی عمل می کند. نتایج نشان می دهد که با تعداد بسیار کمی از تصاویر آموزشی، مدل پیشنهاد شده GD-HASLR بهترین عملکرد را در مقایسه با سایر روش های پیشرفته، از جمله روش های مبتنی بر شبکه عصبی پیچشی دارد. 
مجموعه داده  آموزشی A=\mathbb{R}^{d\times n} در نظر گرفته شده که در آن n تعداد داده های آموزشی و d حاصل ضرب تعداد پیکسل های طول و عرض تصاویر می باشد. داده های آموزشی چهره های طبیعی و بدون انسداد می باشند. y=\mathbb{R}^d یک داده آزمایشی می باشد. می توان از یک ترکیب خطی داده های آموزش برای تخمین زدن داده آزمایش استفاده کرد که شامل یک عبارت خطای L=\mathbb{R}^d نیز می باشد. (شکل 3-16) 
(‏3 11)
y=Ax+L	
که در آن x بردار ضرایب با n بعد می باشد.
 
شکل ‏3 13 - تصویر انسداد از ترکیب خطی تمام چهره های آموزشی در مجموعه داده و یک تصویر L که نشان دهنده انسداد است، تشکیل شده است
برای آنکه شرط تنک بودن به رابطه بالا اضافه شود، مسئله به صورت زیر نوشته می شود:
(‏3 12)
argminxx1   s.t.y-Ax≤ϵ

که در آن \epsilon یک آستانه خطا می باشد. برای تصویر و ورودی و تصاویر مجموعه داده آموزش، گرادیان مرتبه اول، دوم و سوم محاسبه شده و به عنوان ویژگی هر تصویر در نظر گرفته می شود. در ادامه شرط کم رتبه بودن ماتریس ویژگی ها نیز به این رابطه اضافه می شود. با استفاده از روش ضرایب لاگرانژ، رابطه بالا را می توان به صورت یک مسئله بهینه سازی بدون محدودیت نوشت و حل نمود.
(‏3 13)	\mathcal{L}\left(x,L,z\right)=\alphaLM+⬚πλxi+zT(y-Ax-L)+β2y-Ax-L22

که در آن z ضریب لاگرانژ و β عامل مجازات می باشد. پس از بدست آوردن بردار تنک x می توان باقیمانده دسته i ام را به صورت زیر محاسبه نمود:
(‏3 14)
r_i=y-Aδi(x)2

که در آن \delta_i(.) نشان دهنده i امین انتخاب کننده دسته می باشد که فقط ورودی های مربوط به دسته i ام را حفظ می کند و در سایر قسمت ها برابر با صفر می باشد. در نهایت دسته ای که کمترین باقیمانده را داشته باشد، انتخاب می-شود. رویکرد کلی الگوریتم در شکل 3-14 آمده است.
 
شکل ‏3 14- رویکرد کلی الگوریتم GD-HASLR
در سال 2014 J. Li و همکاران در [37] یک روش تشخیص چهره پوشیده شده در پس زمینه پیچیده ارائه کردند. این الگوریتم از دو مرحله تشکیل شده است. در مرحله اول تعیین می کنند که آیا شی یک شخص می باشد یا خیر و در مرحله دوم بررسی می شود که آیا چهره پوشیده شده می باشد یا خیر و در صورت پوشش چهره، نوع پوشش و اینکه پوشیدگی با ماسک، کلاه، عینک یا ... است را مشخص می کند.
در مرحله اول یک رویکرد تشخیص شی در پیش زمینه در حالت پویا و ایستا پیشنهاد شده است. برای تشخیص هدف ایستا از تشخیص مبتنی بر ویژگی HOG استفاده شده است. از آنجا که سرعت HOG نسبتاً پایین است، از LBP به همراه آن نیز استفاده کرده اند. 
در مرحلۀ دوم از طبقه بند Adaboost برای طبقه بندی چهره های پوشیده شده استفاده شده است که برای انواع پوشیدگی آموزش داده شده است.
	چالش کمبود تصاویر آموزشی
در سال 2017 Ya Wang و همکاران در [39] روشی برای تشخیص چهره در دوربین های نظارتی در محیط بدون محدودیت به وسیله شبكه عصبی پیچشی عمیق ارائه دادند. از آنجایی که داده های آموزشی ورودی به مدل از اهمیت بالایی برای تشخیص برخوردار هستند و همچنین به تعداد زیادی از داده های هر دسته برای بهبود عملكرد سامانه نیاز است، نوآوری  این رویکرد، ساختن یک مجموعه داده استاندارد برای شبكه عصبی از روی دوربین های نظارتی در محیط است که در چهار مرحله به صورت زیر ساخته می شوند.
	 با توجه به اینكه تصاویر مورد نظر برای هر فرد در مجموعه فریم های پشت سر هم از یک دوربین موجود است، می-توان مجموعه تصاویر یک فرد را بوسیله ترکیب الگوریتم تشخیص چهره و ردیابی چهره جمع آوری کرد. پس از شناسایی یک چهره، با ردیابی آن به وسیله الگوریتم KCF، مجموعه تصاویری از آن به عنوان یک دسته طبقه بندی می-شود.
 
شکل ‏3 15 - ردیابی، یافتن چهره ها و برچسب زنی
	برخی تصاویر در هر دسته به اشتباه در مرحله اول به عنوان تصویر یک فرد در نظر گرفته شده اند (شکل 3-16).
 
شکل ‏3 16 - تصاویر با حاشیه قرمز رنگ، به اشتباه برچسب زنی شده اند
با استفاده از روش خوشه بندی گراف  روی ویژگی های استخراج شده از شبكه VGG-Face، تشخیص و پاک سازی تصاویر اشتباه انجام می شود. فاصله کسینوسی بین ویژگی های تصاویر چهره محاسبه می شود و اگر این فاصله برای هر دو تصویر کمتر از یک مقدار آستانه باشد، این تصاویر متعلق به یک فرد هستند. با توجه به شکل 3-17 تصویری که بیشترین شباهت را به تصاویر دیگر دارد، به عنوان شاخص برای آن شخص انتخاب می شود.
 
شکل ‏3 17- استفاده از روش خوشه بندی گراف و تعیین تصویر شاخص
	با استفاده از محاسبه فاصله بین هر داده با داده مرکزی و در نظر گرفتن یک آستانه، داده های تكراری در هر دسته مشخص شده و حذف  می شوند.
	با توجه به مقدار داده های درون هر دسته، تصفیه بین دسته ای انجام می شود. اگر مجموعه داده های درون هر دسته کمتر از 100 تصویر باشد، آن دسته از مجموعه داده حذف می شود.
دقت خوشه بندی و جمع آوری مجموعه داده 99.2% شده است. در نهایت از یک مدل پیش آموزش دیده شده شبكه VGG-Face همراه با Fine-tuning برای طبقه بندی تصاویر آزمایشی استفاده شده است که به دقت 92.1% رسیده است.
	چالش منابع محدود
در سال 2012 Tolga Soyata و همکاران در [40] یک روش تشخیص چهره بی درنگ مبتنی بر بینایی ابری  با استفاده از معماری MOCHA ارائه کردند (شکل 3-18). با فراگیر شدن تلفن همراه هوشمند در میان شهروندان، سامانه تشخیص چهره می تواند از همکاری مشترک محاسبات تلفن همراه و رایانش ابری استفاده کند. چالش این سامانه، چگونگی تجزیه انجام وظیفه بین تلفن همراه و فضای ابری، توزیع بار محاسبه در میان سرورهای ابر برای به حداقل رساندن زمان پاسخ با توجه به تأخیر ارتباطات مختلف و قدرت محاسبه سرور می باشد. نتایج نشان می دهد که الگوریتم-های بخش بندی بهینه پردازش بین تلفن همراه و فضای ابری با توجه به زمان تأخیر ناهمگن، توانایی محاسبه را به طور قابل توجهی افزایش می دهند. 
 
شکل ‏3 18 - معماری MOCHA: دستگاه های تلفن همراه از طریق اتصال چندگانه با cloudlet و ابر ارتباط برقرار می کنند
این سامانه از لحاظ ساختار به سه بخش تقسیم می شود:
دستگاه همراه: تلفن های همراه و iPad ها نقش تهیه و ارسال تصاویر را دارند. تصاویر با فرمت RAW فرستاده می-شوند تا قابلیت پیش پردازش بهتری داشته باشند. اگر سرور ابر به دستگاه همراه نزدیک باشد و ارتباط با سرعت بالا امکان پذیر باشد، تصاویر پیش پردازش به سرور فرستاده می شوند. در غیر این صورت مرحله پیش پردازش در دستگاه همراه انجام می شود و فقط اطلاعاتی همچون ویژگی های Haar و طبقه بندها به سرور فرستاده  می شوند. پس از اتمام فرایند تشخیص چهره، نتیجه نهایی برای تلفن همراه فرستاده می شود.
ابر کوچک : سرورها و رایانه هایی که توانایی پردازشی متوسطی دارند، ابر کوچک یا cloudlet نامیده می شوند. این دستگاه ها که به عنوان میان دستگاه های همراه و سرورهای ابری اصلی قرار دارند، مجهز به GPU می باشند تا بتوانند پردازش موازی را در زمان مطلوبی انجام دهند.
ابر: سرورهای ابر دارای توان پردازشی و پاسخگویی بسیار بالا می باشند که بار محاسبات سنگین سامانه را به دوش می کشند و تصمیم گیری نهایی بر روی آن انجام می پذیرد.
در سال 2018 Pengfei Hu و همکاران در [41] یک رویکرد تشخیص چهره مبتنی بر رایانش ابری ارائه کردند. افزایش برنامه های کاربردی در زمینه کلان داده  ها باعث افزایش تقاضای سامانه های شناسایی چهره برای محاسبات قدرتمند و ظرفیت ذخیره سازی بالا می شود. این سامانه به طور کامل از مزایای محاسبات ابری بهره می برد تا به طور موثر توانایی محاسبات و ظرفیت ذخیره سازی را بهبود بخشد. نتایج تجربی نشان می دهد که طرح پیشنهادی عملا امکان-پذیر است و می تواند سرویس شناسایی موثر چهره را فراهم کند. همانطور که در شکل 3-19 مشاهده می شود، تنها تهیه تصویر بر عهده دستگاه سرویس گیرنده می باشد و تمام محاسبات یافتن و شناسایی چهره بر روی ابر انجام می شود.
 
شکل ‏3 19 - نمای کلی سامانه تشخیص چهره مبتنی بر رایانش ابری
در این سامانه تصویر با فرمت RAW برای ابر ارسال شده و برای یافتن چهره از ویژگی های Haar استفاده شده است. سپس عملیات همسان سازی بافت نگار بر روی تصویر چهره اعمال می شود تا بهبود جزیی حاصل شود. سپس از الگوریتم LBP  برای استخراج ویژگی های چهره استفاده شده، برای هر تصویر یک شناسه تولید می گردد و در نهایت با استفاده از فاصله اقلیدسی با شناسه تصاویر موجود در پایگاه داده مطابقت داده می شود. همانطور که در شکل 3-20 مشاهده می شود این سامانه ابری از بخش های سرور مدیریت (MS )، سرور اطلاعات (IS )، سرور شناسایی (RS ) و پایگاه داده تشکیل شده است. به علت قدرت بالای پردازش در سرور ابری، امکان پردازش موازی نیز در این سامانه وجود دارد که باعث افزایش سرعت محاسبات و کاهش زمان پاسخ دهی سامانه می گردد. 
 
شکل ‏3 20 - چارچوب سامانه شناسایی چهره مبتنی بر رایانش ابری
	نتیجه گیری
به تازگی یادگیری عمیق در تشخیص چهره و بسیاری از زمینه های هوش مصنوعی به راه حل غالب تبدیل شده است. ما یک سوال مطرح می کنیم: آیا یادگیری عمیق واقعا مسئله تشخیص چهره را حل می کند؟ چالش روش های یادگیری عمیق در تشخیص چهره چیست؟ 
در مقایسه با تشخیص شیء عمومی، تشخیص چهره به دلیل طیف گسترده ای از تغییرات در ظاهر چهره ها چالش برانگیز است. نورپردازی کنترل نشده، انسداد ناشی از عینک، مو، ریش، کلاه و... ، تاری خارج از تمرکز دوربین، کیفیت پایین تصویر، بالا رفتن سن افراد و کمبود داده های آموزشی از مواردی می باشند که می توانند سامانه تشخیص چهره را با مشکل رو به رو نمایند.
از طرفی اکثر مجموعه داده ها تنها شامل چند هزار عکس می باشد. یک مجموعه داده حاوی اطلاعات بدون محدودیت و مقیاس بزرگ، سامانه چارچوب چهره را به چالش هایی همچون گرایش های شدید، نور کم و تصاویر کوچک و تاریک چهره تبدیل می کند. محققان فرض کرده اند که لایه های عمیق CNN ها می توانند اطلاعات انتزاعی بیشتری مانند هویت، ظاهر و ویژگی ها را رمزگذاری کنند؛ با این حال هنوز هنوز کاملا مطالعه نشده است که لایه ها دقیقا با ویژگی های محلی برای تشخیص مطابقت دارند.
برای شناسایی چهره، عملکرد یادگیری را می توان با یادگیری یک معیار اندازه گیری فاصله متمایز کننده بهبود داد. با این حال، با توجه به محدودیت های حافظه کارت گرافیک ها، نحوه انتخاب جفت ها یا سه گانه های اطلاعاتی و روش های آموزش آنلاین (به عنوان مثال، گرادیان نزولی) در مجموعه داده های بزرگ، هنوز یک مشکل باز است. یکی دیگر از مشکلات چالش برانگیز این است که پردازش ویدیو در شبکه های عمیق را برای استفاده از تجزیه و تحلیل چهره مبتنی بر ویدئو ترکیب کند.  



